{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fede2a-cd34-46b9-9b06-776112f2e680",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Working with HDF5 datasets\n",
    "\n",
    "Unlike the h5py package, which returns `numpy.ndarray` when accessing the values of datasets, the `h5rdmtoolbox` returns `xarray.DataArray` objects ([https://xarray.pydata.org/]). The `xarray.DataArray` object allows to carry attributes with the numpy-like multi-dimensional array. It also supports the concept of dimensions and coordinates, allowing to assign the array axis with meaning ful (meta) data.\n",
    "\n",
    "Let's dive into it and explore the practical implications of retrieving `xarray.DatArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2b312-16d5-4aa7-8f10-9107a2e53c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5rdmtoolbox as h5tbx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc428f1-f2a6-4f4d-bbbf-9880358cff06",
   "metadata": {},
   "source": [
    "Let's create an example file. Note, that we pass `make_scale` and `attach_scale` as arguments to setup the coordinates and their association to the HDF5 dataset \"data\". The useful implications will be visible when we access the dataset values in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf629a23-0162-4d0b-a910-691b4ec97941",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    dsx = h5.create_dataset('x', data=np.linspace(0, 10, 5),\n",
    "                            attrs=dict(units='mm', long_name='x'),\n",
    "                            make_scale=True)\n",
    "    dsy = h5.create_dataset('y', data=np.linspace(0, 5, 11),\n",
    "                            attrs=dict(units='mm', long_name='y'),\n",
    "                            make_scale=True)\n",
    "    h5.create_dataset('vel', data=np.random.random((11, 5)),\n",
    "                      attrs=dict(units='m/s', long_name='velocity'),\n",
    "                      attach_scales=(dsy, dsx))\n",
    "    h5.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2da86-50d5-48c2-a15a-7fce8e06fc66",
   "metadata": {},
   "source": [
    "## Array Slicing\n",
    "\n",
    "Slicing an HDF5 dataset returns a `xarray.DataArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd4492-84ad-4950-81ea-eae066c591e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(h5.hdf_filename) as h5:\n",
    "    data = h5.vel[:]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e1093b-3e45-4d01-8ab6-42a58a2cdf6e",
   "metadata": {},
   "source": [
    "## Advantages of retrieving `xarray.DataArray`\n",
    "\n",
    "Few of the advantages:\n",
    "- attributes (aux. info) with the array `.attrs` (copied from the HDF dataset to the `xarray.DataArray`)\n",
    "- dimensions and coordinates (1D arrays) to address the axis by label rather than by idex\n",
    "- apply operations (computations, visualizations) based on the meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ae071-ef36-46b8-89ec-4df1bc02da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc2472-9494-412d-9d16-396ca8eb2dba",
   "metadata": {},
   "source": [
    "Select subarray by specifying coordinate values for a given axis (coordinate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05311e4-357e-4832-8cf5-752a6de17241",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sel(y=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30dc33-8517-445f-88b9-ac4b9118e339",
   "metadata": {},
   "source": [
    "Plot data by using information from attributes and coorinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4799387-5349-4083-9e79-aa74bb639fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.contourf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0589eb-8d3b-4a1c-bba8-71c528144745",
   "metadata": {},
   "source": [
    "## Cirumnavigate return of `xarray.DataArray` objects\n",
    "\n",
    "In certain cases, there may be no requirement to return `xarray.DataArray` objects, and it may be more convenient to work with the default interface, hence `numpy.array` objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f8b30-bbc4-4f60-b89b-df480508b695",
   "metadata": {},
   "source": [
    "If we got the `xarray` object already, just call the property `.values`. Otherwise, we have the following two options to retrieve `numpy.array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f42721-c7d6-40e9-beed-01a918757e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(h5.hdf_filename) as h5:\n",
    "    data_np = h5.vel.values[:]\n",
    "type(data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3da562-5914-4ed4-9294-d170a5a58a4d",
   "metadata": {},
   "source": [
    "Using the configuration setter just for this code snippet (using context manager syntax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f9ff4-aa61-4539-882d-d8d3f9348592",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.set_config(return_xarray=False):\n",
    "    with h5tbx.File(h5.hdf_filename) as h5:\n",
    "        data_np = h5.vel.values[:]\n",
    "type(data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99459d8c-44a5-4f3a-b2d2-cf555ccd222a",
   "metadata": {},
   "source": [
    "## Selecting data (`.sel`)\n",
    "\n",
    "HDF5 datasets may sometimes be very large. Hence it is ineffcient to slice a larger array and then use the useful method of (selecting)[https://docs.xarray.dev/en/stable/user-guide/indexing.html]. The `h5rdmtoolbox` allows to call `.sel` prior to the above slicing, to reduce the data loaded to the RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c4a7e-68d3-49de-909b-b7a57f806dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(h5.hdf_filename) as h5:\n",
    "    print('available coords to select from: ', h5.vel.coords().keys())\n",
    "    xdata = h5.vel.sel(y=2.0)\n",
    "xdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e04bd-24a2-4c28-bec3-4b1c25ff7d92",
   "metadata": {},
   "source": [
    "## HDF Dataset with ancillary datasets\n",
    "\n",
    "Ancillary datasets, which exist in the HDF5 file and are associated to one dataset. The ancillary datasets must have the same shape as the parent dataset.\n",
    "\n",
    "An common use-case is the association of validation flags or uncertainty data.\n",
    "\n",
    "Let's add a relative uncertainty of 5% to the dataset \"vel\". For this we create the dataset \"uncertainty\" and attach it to the already existing dataset \"vel\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904a8c0-56f4-40c0-bfcc-873576c448e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_uncertainty = np.clip(np.random.normal(loc=0.025, scale=0.001, size=(11, 5)), 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcbf25-71fd-49d3-8f54-92917f9d5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(h5.hdf_filename, mode='r+') as h5:\n",
    "    h5.create_dataset('uncertainty', data=rel_uncertainty,\n",
    "                      units='',\n",
    "                      attach_scales=('y', 'x'))\n",
    "    h5.vel.attach_ancillary_dataset(h5.uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000222e-9906-44b2-904c-c5254b1ca0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5tbx.dump(h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc401dc-9dde-4f5f-b04a-26b681fbfed5",
   "metadata": {},
   "source": [
    "The ancillary dataset will appear as a `xarray` coordinate when the dataset is sliced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1dffc-f602-4e42-b7d9-0993ce3e3c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(h5.hdf_filename) as h5:\n",
    "    u = h5.vel[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce04d0c-b674-4119-baff-917153645778",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(h5.hdf_filename) as h5:\n",
    "    print('available ancillary datasets: ', h5.vel.ancillary_datasets)\n",
    "    data = h5.vel.sel(y=3.1, method='nearest')\n",
    "data.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a65440d-eaaf-4182-945e-2d8275138240",
   "metadata": {},
   "source": [
    "## Conditional data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462dbd2f-1798-4caa-bfbf-be403749045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.File(h5.hdf_filename) as h5:\n",
    "    data = h5.vel[()]\n",
    "\n",
    "# data.uncertainty.plot.hist()\n",
    "data.where(data.uncertainty<0.025).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
