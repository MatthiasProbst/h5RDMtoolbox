{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddcf4ed-d376-4212-82b6-e073a52c6b2a",
   "metadata": {},
   "source": [
    "# Provenance\n",
    "\n",
    "One aspect of data provenance is keeping track of the processing steps applied to data.\n",
    "\n",
    "Next, we will learn how this can be done working with `xarray` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0538f0-8d79-4daf-9ea6-5a355562e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5rdmtoolbox as h5tbx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53509d04-c859-4e4d-befb-1befe3a7b3ed",
   "metadata": {},
   "source": [
    "For the example, let's assume a 3D-velocity field with time, y- and x-dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfae2053-e432-409e-b2d9-ae73e918efd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "using(\"h5rdmtoolbox-tutorial-convention\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = h5tbx.conventions.from_zenodo('https://zenodo.org/record/8301535')\n",
    "\n",
    "h5tbx.use(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061c61d-4433-4973-9c80-d459dff67624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x188faf65790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5tbx.File(data_type='experimental', contact=h5tbx.__author_orcid__) as h5:\n",
    "    h5.create_dataset('time', data=np.linspace(0, 5, 5), standard_name='time', units='s', make_scale=True)\n",
    "    h5.create_dataset('y', data=np.linspace(0, 10, 10), standard_name='y_coordinate', units='m', make_scale=True)\n",
    "    h5.create_dataset('x', data=np.linspace(0, 7, 7), standard_name='x_coordinate', units='m', make_scale=True)\n",
    "    h5.create_dataset('u', data=np.random.rand(5, 10, 7), standard_name='x_velocity', units='m/s', attach_scale=('time', 'y', 'x'))\n",
    "    u = h5.u[:]\n",
    "\n",
    "# plot t=2.5 s:\n",
    "u.sel(time=2.5).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ee0e9-9f72-4fad-895a-3b088208cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox.conventions.standard_names import accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c4e32-82a1-4e3c-af14-e87025ef5c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_processed = u.snt[0:2,...].snt.arithmetic_mean_of(dim='time')\n",
    "\n",
    "def get_dim_shape(da):\n",
    "    return {d: len(da[d]) for d in da.dims}\n",
    "\n",
    "def explain_history(da):\n",
    "    for i, item in enumerate(da.attrs['PROVENANCE']['processing_history']):\n",
    "        print(i, 'applied ', item['name'], ' on array with shape', item['parent']['dims_shape'])\n",
    "        print('  -> ', item['name'])\n",
    "    print('Current shape ', get_dim_shape(da))\n",
    "\n",
    "explain_history(u_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205c895-748b-428b-967a-c9720d9d6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "u_processed.attrs['PROVENANCE']['HDF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868dd9a9-3211-4b2b-977c-bb5b4165e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5tbx.use(None):\n",
    "    with h5tbx.File() as h5:\n",
    "        h5.create_dataset('u_processed', data=u_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435eeeff-6cfe-4e37-92d2-3a25dffcc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "---awd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e37afcf-816c-4c91-aaa6-75e48ec8934b",
   "metadata": {},
   "source": [
    "Let's say we want to compute the time average of the above data, then we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e55be2-e91e-4f56-81ae-1549b40a0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.mean(dim='time', keep_attrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c178f3-339e-4acd-ad87-2e49a96025b4",
   "metadata": {},
   "source": [
    "This leaves us with two issues:\n",
    "- the standard name of the new array is incorrect, it should be \"arithmetic_mean_of_x_velocity\"\n",
    "- information about the original data is lost, e.g. what were the time bounds?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50360e7-0a74-4971-95b2-c8c3fc9feeac",
   "metadata": {},
   "source": [
    "Provenance features must be implemented by the user. With standard names concept, we got such an example. Some of the transformations applicable to standard names can perform mathematical operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92a498-1f2e-45e1-9620-24bbfbed4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox.conventions.standard_names import accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66597e1c-0437-4f68-9b81-9092dbbef771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "class HDF5Provenance:\n",
    "\n",
    "    def __init__(self, data: Dict):\n",
    "        self._data = data\n",
    "\n",
    "    @property\n",
    "    def file(self):\n",
    "        return self._data['HDF']\n",
    "\n",
    "    def get_processing_history(self):\n",
    "        return self._data['SNT_TRANSFORMATION_HISTORY']#_TRANSFORMATION_HISTORY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4ba82-13b5-4344-8bd6-ee1f24eb85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1914476-4fba-48db-b09a-a0035c4dc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89be41-b313-4682-8c1f-585fe1c2cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mean = u.snt.arithmetic_mean_of(dim=('time')).snt.arithmetic_mean_of(dim=('x'))\n",
    "prov = u_mean.snt.get_provenance()\n",
    "\n",
    "print(f'HDF source file: {HDF5Provenance(prov).file[\"filename\"]}')\n",
    "print('Transformation history:')\n",
    "\n",
    "out = ''\n",
    "for item in HDF5Provenance(prov).get_processing_history():\n",
    "    for s in item['parent']['dims_shape'], ' --', item['name'], f'{tuple(item[\"bounds\"].keys())}' ,' --> ':\n",
    "        out += str(s)\n",
    "\n",
    "out += str({d: len(u[d]) for d in u_mean.dims})\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010fada8-ed20-43ac-af66-77f8fc472c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'HDF source file: {HDF5Provenance(prov).file[\"filename\"]}')\n",
    "print('Transformation history:')\n",
    "for item in HDF5Provenance(prov).get_processing_history():\n",
    "    # print(item)\n",
    "    print(item['name'])\n",
    "    print(item['parent'])\n",
    "    print(item['bounds'])\n",
    "    print(item['len'])\n",
    "    # dims = []\n",
    "    # for dim_name, dim_data in v.items():\n",
    "    #     _from = xr.DataArray.from_dict(v[dim_name]['bounds'][0])\n",
    "    #     _to = xr.DataArray.from_dict(v[dim_name]['bounds'][1])\n",
    "    #     _len = HDF5Provenance(prov).get_processing_history()['arithmetic_mean_of'][dim_name]['len']\n",
    "    #     _from_str = f'{h5tbx.get_ureg().Quantity(_from.data[()], _from.units)}'\n",
    "    #     _to_str = f'{h5tbx.get_ureg().Quantity(_to.data[()], _to.units)}'\n",
    "    #     dims.append(f'{_len} data points of \"{dim_name}\" in bounds [{_from_str}, {_to_str}]')\n",
    "    # print(f'  > \"{k}\" over\\n     -', '\\n     - '.join(dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7555c6-f744-4074-97d6-1156d3d52068",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd646ddd-1b9e-440b-a30d-5b97eeedffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff96e3-5e9c-41fb-b418-5cb4dea5f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mean.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169b71a-d7c9-451c-9d8a-f9ae7d4019e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray.from_dict(HDF5Provenance(prov).get_processing_history()['arithmetic_mean_of']['time'][0])\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98eea0-80f8-47ba-9764-ba5c8e9ef0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
