{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd4ad67-62a4-44e2-be29-d50f8ff09310",
   "metadata": {},
   "source": [
    "# Standard Attributes\n",
    "\n",
    "Data alone is meaningless. Only if it is associated with auxiliary data (meta data) it becomes interpretable and (re-)usable for others. In HDF5 files is realized by using **attribute**, which are assigned to groups and datasets. HDF attributes are like dictionaries: You provide a name and a value. However, which name and value you are using is generally up to the you.\n",
    "\n",
    "The `h5RDmtoolbox` let's you specify rules for specific attributes. These attributes are simply called **standard attributes** and can be enabled or disabled and therefore made available to the user or not.\n",
    "\n",
    "If an attribute is addressed by the user, e.g. the attribute `units`, and a standard attribute implementation exists for this name, then the value is processed by the respective rule and the attribute is set or an error is raised in case of a invalid input.\n",
    "\n",
    "Standard attributes can be made required **during dataset creation** for instance. This enforces users to pass certain meta information and validates it at the same time. Consequently data becomes re-usable and explorable.\n",
    "\n",
    "Additionally, so-called [layouts](./layouts.ipynb) can be defined, too. They are used to specify the content of an HDF5 file after it has been written. This concept applies best during file exchange as the layout validates if a file is complete and meets the expertation of the project or collaborative user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc410573-dd0d-4e2e-a513-49607fcfe6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5rdmtoolbox\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mh5tbx\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\programming\\GitHub\\h5RDMtoolbox\\h5rdmtoolbox\\__init__.py:123\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"get the current convention\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conventions\u001b[38;5;241m.\u001b[39mcurrent_convention\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(filename, flt: Union[\u001b[43mDict\u001b[49m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    124\u001b[0m          objfilter: Union[\u001b[38;5;28mstr\u001b[39m, h5py\u001b[38;5;241m.\u001b[39mDataset, h5py\u001b[38;5;241m.\u001b[39mGroup, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m          rec: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    126\u001b[0m          ignore_attribute_error: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m File(filename) \u001b[38;5;28;01mas\u001b[39;00m h5:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;66;03m# TODO return \"offline-datasets or offline-group(s)\". They have the attributs can can be sliced, have ndim, shape, ... etc but when sliced only then the file is opened, data is returned and file is closed again.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m h5\u001b[38;5;241m.\u001b[39mfind(flt, objfilter, rec, ignore_attribute_error)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "import h5rdmtoolbox as h5tbx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffca28f-1840-42e4-a672-b8292554f611",
   "metadata": {},
   "source": [
    "## Defining a new standard attribute\n",
    "\n",
    "Referring to the above example, let's define the standard attribute `units`. Therefore, we need to inherite from the class `StandardAttribute` and provide the methods `set()` and `get()`. The attribute name with which this class is associated is the class name or, if set, the class variable `name` (the latter is recommended to be used):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3296ad-2d4d-4184-9861-1c6763aa32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox import conventions\n",
    "import warnings\n",
    "\n",
    "class SourceAttribute(conventions.StandardAttribute):\n",
    "    \n",
    "    name = 'source'\n",
    "    \n",
    "    def set(self, source_type: str):\n",
    "        if source_type.upper() not in ('NUMERICAL', 'EXPERIMENTAL'):\n",
    "            raise ValueError('Unknown source type')\n",
    "        super().set(source_type)\n",
    "        \n",
    "    def get(self):\n",
    "        source_type = super().get()\n",
    "        if source_type is None:\n",
    "            warnings.warn('No source available')\n",
    "            return\n",
    "        elif source_type.upper() not in ('NUMERICAL', 'EXPERIMENTAL'):\n",
    "            warings.warn(f'Unexpected source type: {source_type}')\n",
    "        return source_type.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc80b7-8880-4414-95b6-803730a499c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from h5rdmtoolbox import conventions\n",
    "import warnings\n",
    "\n",
    "class SourceAttribute(conventions.StandardAttribute):\n",
    "    \n",
    "    name = 'source'\n",
    "    \n",
    "    def set(self, source_type: str):\n",
    "        if source_type.upper() not in ('NUMERICAL', 'EXPERIMENTAL'):\n",
    "            raise ValueError('Unknown source type')\n",
    "        super().set(source_type)\n",
    "        \n",
    "    def get(self):\n",
    "        source_type = super().get()\n",
    "        if source_type is None:\n",
    "            warnings.warn('No source available')\n",
    "            return\n",
    "        elif source_type.upper() not in ('NUMERICAL', 'EXPERIMENTAL'):\n",
    "            warings.warn(f'Unexpected source type: {source_type}')\n",
    "        return source_type.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254bd8ff-1d4f-4e20-aed9-0d488615d284",
   "metadata": {},
   "source": [
    "## List of available conventions\n",
    "\n",
    "It is possible to register conventions, which is the list of standard attributes for the respective HDF objects. A list can be optained by the dictionary `conventons.registered_conventions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3382d99-6c5e-4d81-8894-a95eb8364dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5tbx.conventions.registered_conventions.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794b19d-a950-47d7-8af5-b16b79e70974",
   "metadata": {},
   "source": [
    "Now, we regulated what happens, when this special (standard) attribute is written (`set`) and read (`get`).\n",
    "\n",
    "## Add to a convention\n",
    "Next we need to add this attbribute to a convention and assign it to the `Group` calss and the method `create_dataset` in order to make \"source\" available to the user and enforce its usage.\n",
    "\n",
    "Let's initialize a new convention and register it (make it available in the package):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a6b93-9bf3-45eb-ba88-4930d7b935d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = conventions.Convention('my_convention')\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa28d193-e07f-4264-890f-ca9208c97744",
   "metadata": {},
   "source": [
    "The output shows which attributes are associated with the objects `File`, `Group` and `Dataset` and the methods `__init__`, `create_group` and `create_dataset`. What this exactly means will get clear shortly. Let's add `SourceAttribute` the class `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664bc012-33d8-4ccc-a1fd-ca9516bb26a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv['create_dataset'].add(SourceAttribute,\n",
    "                         add_to_method=True,\n",
    "                         optional=True,\n",
    "                         position={'after': 'data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07018fe-fd14-4f89-984e-115799ef372b",
   "metadata": {},
   "source": [
    "The `SourceAttribute` is now added to the class `Group`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3621cd4-2431-44ad-9896-790a7e7fd89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03099119-4f6a-4e8a-b5a9-5ca40f768468",
   "metadata": {},
   "source": [
    "For now, it is only registered as a property. This means, the user is yet responsible for setting the \"source\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47770902-9682-42a4-8c56-6eead767d241",
   "metadata": {},
   "source": [
    "## Register and enable\n",
    "We need to register the convention `cv` and enable it (and thus enable the \"source\" attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe8700-fc08-49c7-9893-578339248541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv.register()\n",
    "h5tbx.use('my_convention')\n",
    "h5tbx.current_convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53bac0-5b03-4fb8-9986-3aadf200729e",
   "metadata": {},
   "source": [
    "## Example:\n",
    "Let's create a dataset and get the source. As we do not pass the argument `source` (we set it to optional) and we do not set it via the attribute manager, we expect a warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b1a22-009a-404b-8ba8-f705a1864e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    ds = h5.create_dataset('data', (4, 5))\n",
    "    print(ds.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaeb426-4113-4e50-95bf-92d1704507ee",
   "metadata": {},
   "source": [
    "We may pass \"source\" directly as an argument or via \"attrs\". Both of which will check if the source is \"numerical\" or \"experimental\", thus the `set()` method is called in both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef94ffa-9ed0-44f8-9f79-ee7012cc3bec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    ds1 = h5.create_dataset('data1', (4, 5), attrs={'source': 'numerical'})\n",
    "    ds2 = h5.create_dataset('data2', (4, 5), source='experimental')\n",
    "    # two example that fail:\n",
    "    try:\n",
    "        h5.create_dataset('data3', (4, 5), attrs={'source': 'model-based'})\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        h5.create_dataset('data4', (4, 5), source='model-based')\n",
    "    except ValueError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910337a6-766d-47f8-8c20-6f3f39ca58fe",
   "metadata": {},
   "source": [
    "Until now, the source attribute was **optional**. We want to enforce the use, so let's change this property of the standard attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1bafe-795d-4824-aa91-0fda3c1c0f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv.make_required('create_dataset', 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71233e6a-5a54-46eb-a854-9bc90c0d687a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691035f-f4e6-4e42-8707-c1ddf53a04f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    try:\n",
    "        ds = h5.create_dataset('data', (4, 5))\n",
    "    except h5tbx.conventions.StandardAttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518cfdd-b28c-4917-af5e-ac9d239de346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    ds = h5.create_dataset('data', (4, 5), source='Experimental')\n",
    "    ds.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af7d15-bd56-4871-a010-1c5f317d1936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f183cdae-4f5b-49be-883e-a9f816ba06f0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
