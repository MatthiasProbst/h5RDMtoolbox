{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd4ad67-62a4-44e2-be29-d50f8ff09310",
   "metadata": {},
   "source": [
    "# Standard Attributes\n",
    "\n",
    "Data gets its real value through meta data. In HDF5 files this is done through attributes. A name for an attribute can generally be freely selected. Its value is typically an interger or a string (other data types are possible but out of the packages scope and concept at this stage). Multiple attributes are possible per HDF5 dataset or group. We believe, that by standardizing the use of attributes, the FAIRness of data significantly is improved. Only when all users agree on the same minimum set of attributes data become explorable and automatically processable by machines.\n",
    "\n",
    "Standard attributes can be made required during dataset or group creation. As there might always be a work-around, [layouts](./layouts.ipynb) can be used to validate the file meta-content during file exchanged. Invalid files would be rejected and missing (meta) data needed to be updated.\n",
    "\n",
    "Thus, to summarize, the file (content) is only useful to others (and software!), if data is described in a way, everybody in the community/project/collaboration agreed on. Two  goals must be achieved:\n",
    "1. Users are enforced to use these attributes\n",
    "2. Attributes and their values are set according in a way excepted by a community or by collaborators (mainly syntax)\n",
    "\n",
    "Instead of inherting inheriting from the base class `h5py.Group` and adjusting the method `create_dataset` according to user-defined attributes, we flexible enabling and disabling of specific attributes during run-time. This only requires implementing the attribute `set` and `get` methods of attributes but no further code manipulation of the core implementation.\n",
    "\n",
    "The following explains the usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc410573-dd0d-4e2e-a513-49607fcfe6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07_09:51:57,819 DEBUG    [__init__.py:36] changed logger level for h5rdmtoolbox from 20 to DEBUG\n"
     ]
    }
   ],
   "source": [
    "import h5rdmtoolbox as h5tbx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aa9a65-860e-4045-b2ea-c8250e970fd2",
   "metadata": {},
   "source": [
    "## Standard Attributes\n",
    "\n",
    "A standard attribute can be defined by inheriting from the class `StandardAttribute`. To control the processed data, which means to evaluate the user input and control return values, we need to provide the methods `set()` and `get()` and a `name`. To make it available for use it must be registerde (added) to a convention which then is enabled. Will walk though all that in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254bd8ff-1d4f-4e20-aed9-0d488615d284",
   "metadata": {},
   "source": [
    "## List of available conventions\n",
    "\n",
    "It is possible to register conventions, which is the list of standard attributes for the respective HDF objects. A list can be optained by the dictionary `conventons.registered_conventions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3382d99-6c5e-4d81-8894-a95eb8364dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['h5py', 'tbx'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5tbx.conventions.registered_conventions.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffca28f-1840-42e4-a672-b8292554f611",
   "metadata": {},
   "source": [
    "## Definition of a standard attribute\n",
    "Let's say we want to enforce the user to store the type of data with each dataset, e.g. whether it is from a numerical or experimental source. We call this attribute \"source\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cc80b7-8880-4414-95b6-803730a499c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from h5rdmtoolbox import conventions\n",
    "import warnings\n",
    "\n",
    "class SourceAttribute(conventions.StandardAttribute):\n",
    "    \n",
    "    name = 'source'\n",
    "    \n",
    "    def set(self, source_type: str):\n",
    "        if source_type.upper() not in ('NUMERICAL', 'EXPERIMENTAL'):\n",
    "            raise ValueError('Unknown source type')\n",
    "        super().set(source_type)\n",
    "        \n",
    "    def get(self):\n",
    "        source_type = super().get()\n",
    "        if source_type is None:\n",
    "            warnings.warn('No source available')\n",
    "            return\n",
    "        elif source_type.upper() not in ('NUMERICAL', 'EXPERIMENTAL'):\n",
    "            warings.warn(f'Unexpected source type: {source_type}')\n",
    "        return source_type.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794b19d-a950-47d7-8af5-b16b79e70974",
   "metadata": {},
   "source": [
    "Now, we regulated what happens, when this special (standard) attribute is written (`set`) and read (`get`).\n",
    "\n",
    "## Add to a convention\n",
    "Next we need to add this attbribute to a convention and assign it to the `Group` calss and the method `create_dataset` in order to make \"source\" available to the user and enforce its usage.\n",
    "\n",
    "Let's initialize a new convention and register it (make it available in the package):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04a6b93-9bf3-45eb-ba88-4930d7b935d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mConvention(my_convention)\u001b[0m\u001b[1m\n",
       "> Properties\u001b[0m: (\u001b[3mNothing registered\u001b[0m)\u001b[1m\n",
       "> Methods\u001b[0m:"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = conventions.Convention('my_convention')\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa28d193-e07f-4264-890f-ca9208c97744",
   "metadata": {},
   "source": [
    "The output shows which attributes are associated with the objects `File`, `Group` and `Dataset` and the methods `__init__`, `create_group` and `create_dataset`. What this exactly means will get clear shortly. Let's add `SourceAttribute` the class `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664bc012-33d8-4ccc-a1fd-ca9516bb26a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv['create_dataset'].add(SourceAttribute,\n",
    "                         add_to_method=True,\n",
    "                         optional=True,\n",
    "                         position={'after': 'data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07018fe-fd14-4f89-984e-115799ef372b",
   "metadata": {},
   "source": [
    "The `SourceAttribute` is now added to the class `Group`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3621cd4-2431-44ad-9896-790a7e7fd89a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mConvention(my_convention)\u001b[0m\u001b[1m\n",
       "> Properties\u001b[0m:\n",
       "Dataset:\n",
       "    * source: SourceAttribute\u001b[1m\n",
       "> Methods\u001b[0m:\n",
       "  Group.create_dataset():\n",
       "    * source (optional)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03099119-4f6a-4e8a-b5a9-5ca40f768468",
   "metadata": {},
   "source": [
    "For now, it is only registered as a property. This means, the user is yet responsible for setting the \"source\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47770902-9682-42a4-8c56-6eead767d241",
   "metadata": {},
   "source": [
    "## Register and enable\n",
    "We need to register the convention `cv` and enable it (and thus enable the \"source\" attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35fe8700-fc08-49c7-9893-578339248541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv.register()\n",
    "h5tbx.use('my_convention')\n",
    "h5tbx.current_convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53bac0-5b03-4fb8-9986-3aadf200729e",
   "metadata": {},
   "source": [
    "## Example:\n",
    "Let's create a dataset and get the source. As we do not pass the argument `source` (we set it to optional) and we do not set it via the attribute manager, we expect a warning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299b1a22-009a-404b-8ba8-f705a1864e29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\da4323\\AppData\\Local\\Temp\\ipykernel_25392\\272882550.py:16: UserWarning: No source available\n",
      "  warnings.warn('No source available')\n"
     ]
    }
   ],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    ds = h5.create_dataset('data', (4, 5))\n",
    "    print(ds.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaeb426-4113-4e50-95bf-92d1704507ee",
   "metadata": {},
   "source": [
    "We may pass \"source\" directly as an argument or via \"attrs\". Both of which will check if the source is \"numerical\" or \"experimental\", thus the `set()` method is called in both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ef94ffa-9ed0-44f8-9f79-ee7012cc3bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07_17:56:58,573 ERROR    [core.py:637] Could not set attributes {'source': 'model-based'} for dataset data3\n",
      "2023-05-07_17:56:58,573 ERROR    [core.py:637] Could not set attributes {'source': 'model-based'} for dataset data3\n",
      "2023-05-07_17:56:58,577 ERROR    [core.py:637] Could not set attributes {'source': 'model-based'} for dataset data4\n",
      "2023-05-07_17:56:58,577 ERROR    [core.py:637] Could not set attributes {'source': 'model-based'} for dataset data4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown source type\n",
      "Unknown source type\n"
     ]
    }
   ],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    ds1 = h5.create_dataset('data1', (4, 5), attrs={'source': 'numerical'})\n",
    "    ds2 = h5.create_dataset('data2', (4, 5), source='experimental')\n",
    "    # two example that fail:\n",
    "    try:\n",
    "        h5.create_dataset('data3', (4, 5), attrs={'source': 'model-based'})\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        h5.create_dataset('data4', (4, 5), source='model-based')\n",
    "    except ValueError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910337a6-766d-47f8-8c20-6f3f39ca58fe",
   "metadata": {},
   "source": [
    "Until now, the source attribute was **optional**. We want to enforce the use, so let's change this property of the standard attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb1bafe-795d-4824-aa91-0fda3c1c0f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv.make_required('create_dataset', 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71233e6a-5a54-46eb-a854-9bc90c0d687a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mConvention(my_convention)\u001b[0m\u001b[1m\n",
       "> Properties\u001b[0m:\n",
       "Dataset:\n",
       "    * source: SourceAttribute\u001b[1m\n",
       "> Methods\u001b[0m:\n",
       "  Group.create_dataset():\n",
       "    * source"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e691035f-f4e6-4e42-8707-c1ddf53a04f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard attribute \"source\" is required but not provided.\n"
     ]
    }
   ],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    try:\n",
    "        ds = h5.create_dataset('data', (4, 5))\n",
    "    except h5tbx.conventions.StandardAttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d518cfdd-b28c-4917-af5e-ac9d239de346",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"/data\"\n",
      "---------------\n",
      "*shape:        (4, 5)\n",
      "*dtype:        float32\n",
      "*compression:  gzip (5)\n",
      "source:        EXPERIMENTAL\n"
     ]
    }
   ],
   "source": [
    "with h5tbx.File() as h5:\n",
    "    ds = h5.create_dataset('data', (4, 5), source='Experimental')\n",
    "    ds.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af7d15-bd56-4871-a010-1c5f317d1936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
