{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e482422-c2bb-4606-b3e1-c7a95ac1ca2d",
   "metadata": {},
   "source": [
    "# Multiple planes to HDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656992bf-ee83-4447-80bc-fa695b2d41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox import x2hdf, tutorial, H5PIV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a61b8-650a-4a0d-af61-878d86b3c250",
   "metadata": {},
   "source": [
    "To convert a multiple planes to a single HDF file (multiplane-file), you must provide the plane folders containing the netCDF4 files.<br>\n",
    "**For building a multiplane-file, there are a few scenarios to be aware of which will result in different setups of the HDF file structure!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2362c152-af1c-4262-87c4-26e5cd6b8459",
   "metadata": {},
   "source": [
    "## Planes with unequal recording frequency\n",
    "\n",
    "If all planes (in this tutorials two planes) are recorded with **different** measurement frequencies (laser may be triggered leading to slight time differences while average frequency is similar!), then data variables cannot be packed into a **single array** because the time vector is different for each plane. Thus, groups are generated for each plane where each data variable has shape (`nt`, `ny`, `nx`). Here, the number of time steps (`nt`) could also be different for each plane. However, assuming, recording physically/conceptionally belongs to the same \"case\" it is still reasonable to pack all data in one file. **The time-averaged data is in one data array** having the shape (`nz`, `ny`, `nx`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474121d4-2d37-46ac-9b83-2768285aeca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane0_dir, plane1_dir, plane2_dir = tutorial.PIVview.get_multiplane_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee751cd-8377-48ed-96c2-e0d09e20cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_mplane_uef = x2hdf.PIVMultiPlane([plane0_dir, plane1_dir], time_information=[5, 5.2])  # force different planes by passing different meas. freqs.\n",
    "piv_mplane_uef.convert()\n",
    "print(f'conversion time: {piv_mplane_uef.conversion_time}, generated file: {piv_mplane_uef.hdf_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84fd47-db8e-4a58-b945-089aac26ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with H5PIV(piv_mplane_uef.hdf_filename, 'r') as h5m:\n",
    "    h5m.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0eb02-a9bb-45f2-81d7-ced83ce6e913",
   "metadata": {},
   "source": [
    "## Planes with equal recording frequency\n",
    "\n",
    "If all planes (in this tutorials two planes) are recorded with the same measurement frequency, then data variables can be packed into a **single array** with shape (`nz`, `nt`, `ny`, `nx`), which in this tutorial is (2, 5, 110, 127). The time-averaged data has shape (`nz`, `ny`, `nx`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19110e5-6f69-45e4-8aac-765b64adf493",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv_mplane_ef = x2hdf.PIVMultiPlane([plane0_dir, plane1_dir], time_information=[5, 5])\n",
    "piv_mplane_ef.convert()\n",
    "print(f'conversion time: {piv_mplane_ef.conversion_time}, generated file: {piv_mplane_ef.hdf_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc59a49-7c86-46dd-b65c-eee31b50640d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with H5PIV(piv_mplane_ef.hdf_filename, 'r') as h5m:\n",
    "    h5m.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470fad15-5d08-474a-a9f2-58e10ff4f940",
   "metadata": {},
   "source": [
    "---\n",
    "## Additional Functionalities of the package\n",
    "\n",
    "1. computing additional (intermediate) measurement planes\n",
    "2. combining the intermediate planes with the measured planes to a single new, \"virtual\" multi-plane file\n",
    "\n",
    "Final, folder/file structure will look like:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f5efdc9-c953-4142-a0a6-5f19901b3c4a",
   "metadata": {},
   "source": [
    "rootdir\n",
    " |---plane1\n",
    " |     |--- 001.nc\n",
    " |     |--- 002.nc\n",
    " |---plane2\n",
    " |     |--- 001.nc\n",
    " |     |--- 002.nc\n",
    " rootdir_interpolated_planes/multi_plane_name_nplanes4.hdf  # contains only interpolated planes\n",
    " mplane.hdf   # the original measurement HDF file (this file should be created once and then never changed, other files can be generated again and added with more data)\n",
    " mplane.vhdf  # the virtual hdf file containing measurement and interpolated planes using Virtual Datasets (VDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba214c7e-70f5-4b84-9155-bc8f07b9487e",
   "metadata": {},
   "source": [
    "Now let's generate **intermediate** planes by interpolating them.  The following builds 6 equally spaced z-planes. As this includes the outer two (measured) planes, only 4 planes will be interpolated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466c458-11ae-40e1-8993-a868578cdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with H5PIV(piv_mplane_ef.hdf_filename, 'r+') as h5m:\n",
    "    h5m.dump()\n",
    "    h5m.z[:] = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab0f666-c990-41e5-ac0b-f7eb3f3e753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipfile = piv_mplane_ef.compute_intermediate_plane(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b080b7-4df1-45bd-b658-cd6ce68d28fb",
   "metadata": {},
   "source": [
    "Note that the original measurement file had two planes. The upper method generated actually not 6 but 4 planes because the outer ones already exist in the measurement file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b05a8c-43ce-413f-b4cd-471c48f9cff4",
   "metadata": {},
   "source": [
    "As the two files are separated, we now create a multi-plane file that has all original and interpolated planes in one file. We call such a case a **virtual case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce44f1-b7f3-4b9f-ab4c-a080f9550728",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcase_name = piv_mplane_ef.build_virtual_mplane_file(ipfile)  # pass the just created file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796617f-85a8-4911-92f9-e2c832ad05a0",
   "metadata": {},
   "source": [
    "---\n",
    "## Converting a PIVview \"average dat\" file\n",
    "There are three \"average\" files in pivview \"\\*reyn.dat\", \"\\*rms.dat\", \"\\*avg.dat\". The latter (\"\\*avg.dat\") **must** be exist for the following method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe78e8-8ec6-47f2-a203-461e99818ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox.x2hdf.piv2hdf.pivview.plane import build_plane_hdf_from_average_dat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02cc981-945c-4fa5-a0ba-1054473500ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_filename = tutorial.PIVview.get_avg_file()\n",
    "hdf_file = build_plane_hdf_from_average_dat_files(avg_filename, None, None,\n",
    "                                                  target=str(avg_filename).replace('.dat', '.hdf'))  # reyn and rms file don't exist, so pass None!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322c4d0-5d8f-4c5f-ae67-5f04a2ad3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with H5PIV(hdf_file, 'r') as h5:\n",
    "    h5.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b6739-e259-4391-a420-fcdb0c00087f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
