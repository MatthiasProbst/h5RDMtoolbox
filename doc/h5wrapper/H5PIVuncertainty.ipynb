{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1d5cf0-4da7-42a0-a900-3c3223810bb2",
   "metadata": {},
   "source": [
    "# Computing PIV uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d6c0a-bbda-4595-abfa-4e0548a00c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5rdmtoolbox.h5wrapper import H5PIV\n",
    "from h5rdmtoolbox import tutorial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b0a3b-f652-4ac4-bc4f-9d68035e6869",
   "metadata": {},
   "source": [
    "Get an example HDF filename from the ILA vortex pair example (https://www.pivtec.com/pivview.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0afa19e-eba8-4cc5-8b77-880711f139a1",
   "metadata": {},
   "source": [
    "To compute the uncertainty of a PIV measurement, we need to gather some specific datasets, namely the at minimum the pixel coordinates, the displacements and the raw images. The class property `UncertaintyDataset` does this for us. Calling it will return a `xarray.Dataset` with the displacement variables.\n",
    "\n",
    "Let's load the vortex example and fetch image A and imabe B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da9a9e-6f77-4e4a-9fdd-b1b04927dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tutorial.get_H5PIV('vortex_snapshot', 'r+') as h5:\n",
    "    disp = h5.DisplacementVector[:,:]\n",
    "    imgA = h5.imgA[:,:]\n",
    "    imgB = h5.imgB[:,:]\n",
    "disp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557ccfe-c739-478e-ad87-a128df216a9d",
   "metadata": {},
   "source": [
    "The uncertainty dataset has the coordinates `x` and `y`, the displacements arrays `dx` and `dy` but also the pixel coordinates `ix` and `iy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf3f79-2ae3-4eb4-af65-46f302e399c5",
   "metadata": {},
   "source": [
    "Next, let's create a more or less random uncertainty method. In this example we do not compute the real error but assume one, just to explain the workflow of cumputing the uncertainty from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd9084-41bc-4d0b-8388-a6519c57fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_uncertainty_method(uds, imgA, imgB):\n",
    "    \"\"\"\n",
    "    Dummy uncertainty method for this tutorial.\n",
    "    Returns the same dataset but with added uncertainties\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    uds: XRUncertaintyDataset\n",
    "        The uncertainty dataset containing, x, y, ix, iy, dx, dy, ...\n",
    "    imgA: np.ndarray\n",
    "        2d PIV image A. Will not be touch in this example\n",
    "    imgB: np.ndarray\n",
    "        2d PIV image B. Will not be touch in this example\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    uds: XRUncertaintyDataset    \n",
    "    \"\"\"\n",
    "    import xarray as xr\n",
    "    xerr = 0.05\n",
    "    yerr = 0.075\n",
    "    udx = np.abs(uds.dx)*xerr\n",
    "    uds['udx'] = xr.DataArray(dims=uds.dx.dims, data=udx,\n",
    "                                        attrs={'standard_name': f'uncertainty_of_{uds.dx.standard_name}',\n",
    "                                               'units': 'pixel',\n",
    "                                               'piv_uncertainty_method': 'my_uncertainty_method'})\n",
    "    udy = np.abs(uds.dy)*yerr\n",
    "    uds['udy'] = xr.DataArray(dims=uds.dy.dims, data=udy,\n",
    "                                        attrs={'standard_name': f'uncertainty_of_{uds.dy.standard_name}',\n",
    "                                               'units': 'pixel',\n",
    "                                               'piv_uncertainty_method': 'my_uncertainty_method'})\n",
    "    return uds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9e7c1-76e1-4309-bbd3-5b5df9711d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0e463-34ed-4302-89da-6d4b206dd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "un = disp.compute_uncertainty(my_uncertainty_method, imgA, imgB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241d804-1b25-469a-a845-57889e31dab9",
   "metadata": {},
   "source": [
    "The `XRUncertaintyDataset` not got some more datasets and the uncertainty `DataArray` `delta_dx` and `delta_dy`\n",
    "\n",
    "Now, let's plot the magnitude of the displacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b3bdd-ffa9-4b78-b6af-eea9c331011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "un.compute_magnitude()\n",
    "_ = un.magnitude[:].plot.contourf(vmax=6, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb516c-8767-4949-b019-18c7bffdfbab",
   "metadata": {},
   "source": [
    "Let's have a look at the `udx` dataset of the error without the extreme values which may be wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c513e-c08c-4f60-8664-a5744c14ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un.get_by_attribute('standard_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6dcf0d-b729-4894-b3de-77af51613f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un.get_by_standard_name('uncertainty_of_x_displacement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03be675-113d-43dc-ac87-f8a54bc59756",
   "metadata": {},
   "outputs": [],
   "source": [
    "udx = un.get_by_standard_name('uncertainty_of_x_displacement')\n",
    "_ = udx.where(np.abs(udx) < 20).plot.contourf()\n",
    "print(f'Error in x-direction: {udx.mean().values}')\n",
    "print(f'Absolute relative error in x-direction: {np.divide(udx, np.abs(un.dx)).mean().values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497ab65-f926-41a0-bf68-0a0da31e55b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with H5PIV(h5.hdf_filename, 'r+') as h5:\n",
    "    h5.create_group('uncertainty', overwrite=True)\n",
    "    h5['uncertainty'].create_dataset('delta_dx', data=un.get_by_standard_name('uncertainty_of_x_displacement'), overwrite=True)\n",
    "    h5['uncertainty'].create_dataset('delta_dy', data=un.get_by_standard_name('uncertainty_of_x_displacement'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17c34e-6f7b-406f-9f5a-df178d015ac1",
   "metadata": {},
   "source": [
    "Let's write the data into the HDF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba84f8-50fe-4270-bf26-47c9a97782a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with H5PIV(h5.hdf_filename, 'r+') as h5:\n",
    "    h5.dump()\n",
    "    h5.uncertainty.delta_dx[:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae8089-0858-484c-8d20-37b422c72d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137bcae3-dfce-4ed5-94c7-9462ae14723d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
